{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c82564aa",
   "metadata": {},
   "source": [
    "# CBLOF nos 15 primeiros\n",
    "Teste do SUOD  para comparação e seleção dos integrantes do aplicativo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97204ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [material, acuracia, recall, tempo]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score,recall_score\n",
    "from pyod.utils.data import evaluate_print\n",
    "import time\n",
    "\n",
    "# Importa bibliotecas do PyOD com os algoritmos de detecção de anomalias\n",
    "from pyod.models.inne import INNE\n",
    "from pyod.models.abod import ABOD\n",
    "from pyod.models.cblof import CBLOF\n",
    "from pyod.models.knn import KNN\n",
    "from pyod.models.lof import LOF\n",
    "from pyod.models.pca import PCA\n",
    "from pyod.models.sampling import Sampling\n",
    "from pyod.models.ecod import ECOD\n",
    "from pyod.models.copod import COPOD\n",
    "from pyod.models.suod import SUOD\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "tabelafinal = pd.DataFrame(columns=['material','acuracia','recall','tempo'])\n",
    "print(tabelafinal)\n",
    "      \n",
    "def carrega_material(path,material):\n",
    "    arquivo = str(material)+\".csv\"\n",
    "    csv_path = os.path.join(path,arquivo)\n",
    "    df = pd.read_csv(csv_path)\n",
    "    ## Retira os campos que não serão utilizados no treinamento\n",
    "    df = df.drop(['licitacao_contrato'],axis=1)\n",
    "    df = df.drop(['id'],axis=1)\n",
    "    df = df.drop(['data'],axis=1)\n",
    "    df = df.drop(['catmat_id'],axis=1)\n",
    "    df = df.drop(['unidade'],axis=1)\n",
    "    df = df.drop(['valor_total'],axis=1)\n",
    "    df = df.drop(['municipio_uasg'],axis=1)\n",
    "    df = df.drop(['municipio_fornecedor'],axis=1)\n",
    "    return df     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d492166",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import pymysql\n",
    "from sqlalchemy.dialects.mysql import insert\n",
    "import pandas as pd\n",
    "sqlEngine       = create_engine('mysql+pymysql://siasg:siasg@192.168.2.135/siasg', pool_recycle=3600)\n",
    "dbConnection    = sqlEngine.connect()\n",
    "itens = pd.read_sql(\"SELECT * from siasg.itens\", dbConnection);\n",
    "\n",
    "maioresitens = pd.read_sql(\"SELECT catmat_id, count(*) from siasg.itens where valor_unitario>0 and catmat_id!=0 group by catmat_id order by count(*) desc\", dbConnection);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e6c63a",
   "metadata": {},
   "source": [
    "# Recuperação dos dados a serem utilizados na avaliação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d428b32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indice: 0\n",
      "104671\n",
      "iniciando treinamento 1\n",
      "Acurácia: 0.9423344727180656\n",
      "Recall: 0.3594936708860759\n",
      "2.601250171661377\n",
      "iniciando treinamento 2\n",
      "Acurácia: 0.9434738574503102\n",
      "Recall: 0.3848101265822785\n",
      "0.6507680416107178\n",
      "iniciando treinamento 3\n",
      "Acurácia: 0.9448031396379288\n",
      "Recall: 0.3721518987341772\n",
      "0.6173994541168213\n",
      "Acurácia média: 0.9435371566021015\n",
      "Recall médio: 0.3721518987341772\n",
      "3.9182584285736084\n",
      "Indice: 1\n",
      "150658\n",
      "iniciando treinamento 1\n",
      "Acurácia: 0.9691538859210753\n",
      "Recall: 1.0\n",
      "0.602665901184082\n",
      "iniciando treinamento 2\n",
      "Acurácia: 0.9789763915216267\n",
      "Recall: 1.0\n",
      "0.6352145671844482\n",
      "iniciando treinamento 3\n",
      "Acurácia: 0.974495950370498\n",
      "Recall: 1.0\n",
      "0.6166884899139404\n",
      "Acurácia média: 0.9742087426044\n",
      "Recall médio: 1.0\n",
      "1.9170804023742676\n",
      "Indice: 2\n",
      "445485\n",
      "iniciando treinamento 1\n",
      "Acurácia: 0.9919028340080972\n",
      "Recall: 1.0\n",
      "0.6960897445678711\n",
      "iniciando treinamento 2\n",
      "Acurácia: 0.951417004048583\n",
      "Recall: 1.0\n",
      "0.7326724529266357\n",
      "iniciando treinamento 3\n",
      "Acurácia: 0.979757085020243\n",
      "Recall: 1.0\n",
      "0.7260959148406982\n",
      "Acurácia média: 0.9743589743589745\n",
      "Recall médio: 1.0\n",
      "2.170534610748291\n",
      "Indice: 3\n",
      "402920\n",
      "iniciando treinamento 1\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Could not form valid cluster separation. Please change n_clusters or change clustering method",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 43\u001b[0m\n\u001b[0;32m     40\u001b[0m y_train, y_test \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39miloc[train_index], y\u001b[38;5;241m.\u001b[39miloc[test_index]\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m# Treinar o modelo\u001b[39;00m\n\u001b[1;32m---> 43\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# Fazer as previsões\u001b[39;00m\n\u001b[0;32m     46\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32m~\\.conda\\envs\\Mestrado310\\lib\\site-packages\\pyod\\models\\cblof.py:194\u001b[0m, in \u001b[0;36mCBLOF.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    189\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe chosen clustering for CBLOF forms \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m clusters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    190\u001b[0m                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhich is inconsistent with n_clusters (\u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m).\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    191\u001b[0m                   \u001b[38;5;28mformat\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_clusters_, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_clusters))\n\u001b[0;32m    193\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_cluster_centers(X, n_features)\n\u001b[1;32m--> 194\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_small_large_clusters\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    196\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecision_scores_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decision_function(X,\n\u001b[0;32m    197\u001b[0m                                                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcluster_labels_)\n\u001b[0;32m    199\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_decision_scores()\n",
      "File \u001b[1;32m~\\.conda\\envs\\Mestrado310\\lib\\site-packages\\pyod\\models\\cblof.py:292\u001b[0m, in \u001b[0;36mCBLOF._set_small_large_clusters\u001b[1;34m(self, n_samples)\u001b[0m\n\u001b[0;32m    290\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clustering_threshold \u001b[38;5;241m=\u001b[39m beta_list[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    291\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 292\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not form valid cluster separation. Please \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    293\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchange n_clusters or change clustering method\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    295\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msmall_cluster_labels_ \u001b[38;5;241m=\u001b[39m sorted_cluster_indices[\n\u001b[0;32m    296\u001b[0m                              \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clustering_threshold:]\n\u001b[0;32m    297\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlarge_cluster_labels_ \u001b[38;5;241m=\u001b[39m sorted_cluster_indices[\n\u001b[0;32m    298\u001b[0m                              \u001b[38;5;241m0\u001b[39m:\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clustering_threshold]\n",
      "\u001b[1;31mValueError\u001b[0m: Could not form valid cluster separation. Please change n_clusters or change clustering method"
     ]
    }
   ],
   "source": [
    "##Carrega os dados do item\n",
    "for index, row in maioresitens.iterrows():\n",
    "    print(f'Indice: {index}')\n",
    "    iniciomaterial = time.time()\n",
    "    catmat = row['catmat_id']\n",
    "    df=carrega_material(\".\",catmat)  \n",
    "    print(catmat)\n",
    "    # Separação do Label dos dados\n",
    "    x = df.iloc[:, :-1]\n",
    "    y = df.iloc[:, -1]\n",
    "    #if index<2:\n",
    "    #    continue\n",
    "    detector_list = [\n",
    "             INNE(contamination=0.05, n_estimators=50, random_state= 69), \n",
    "             ABOD(contamination=0.05, method= 'default', n_neighbors=20),\n",
    "             CBLOF(contamination=0.05, n_clusters=2),\n",
    "             KNN(contamination=0.05, leaf_size=10, method='largest', n_neighbors=10),\n",
    "             LOF(contamination=0.05, leaf_size=1, n_neighbors=34),  \n",
    "             PCA(contamination=0.05, n_components=3, n_selected_components=1),\n",
    "             Sampling(contamination=0.05, subset_size=10),\n",
    "             ECOD(contamination=0.09),\n",
    "             COPOD(contamination=0.12)\n",
    "    ]\n",
    "\n",
    "    # Inicializar o modelo SUOD\n",
    "    model = CBLOF(contamination=0.05, n_clusters=2)\n",
    "\n",
    "    # Definir a validação cruzada estratificada\n",
    "    cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=69)\n",
    "\n",
    "    acuracia=[]\n",
    "    recall=[]\n",
    "\n",
    "    # Loop para treinar e testar o modelo\n",
    "    k=1\n",
    "    for train_index, test_index in cv.split(x,y):\n",
    "        iniciofold = time.time()\n",
    "        print('iniciando treinamento '+str(k))\n",
    "        X_train, X_test = x.iloc[train_index], x.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        # Treinar o modelo\n",
    "        model.fit(X_train)\n",
    "\n",
    "        # Fazer as previsões\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        # Calcular a acurácia\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        print(f'Acurácia: {acc}')\n",
    "        acuracia.append(acc)\n",
    "\n",
    "        # Calcular o Recall\n",
    "        rec = recall_score(y_test, y_pred)\n",
    "        print(f'Recall: {rec}')\n",
    "        recall.append(rec)\n",
    "        fimfold = time.time()\n",
    "        tempofold = fimfold-iniciofold\n",
    "        print(tempofold)\n",
    "        k+=1\n",
    "\n",
    "    acuracia_media = sum(acuracia) / len(acuracia)\n",
    "    recall_medio = sum(recall) / len(recall)\n",
    "\n",
    "\n",
    "    print(f'Acurácia média: {acuracia_media}')\n",
    "    print(f'Recall médio: {recall_medio}')\n",
    "    fim = time.time()\n",
    "    tempo = fim-iniciomaterial\n",
    "    print(tempo)\n",
    "    \n",
    "    # Grava os resultados da avaliação na tabela final\n",
    "    tabelafinal.loc[len(tabelafinal.index)] = [catmat,acuracia_media,recall_medio,tempo] \n",
    "    if index==9:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3a850f",
   "metadata": {},
   "source": [
    "# Imprime a tabela final de avaliação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e318a885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   material  acuracia    recall     tempo\n",
      "1  150658.0  0.974209  1.000000  1.917080\n",
      "2  445485.0  0.974359  1.000000  2.170535\n",
      "0  104671.0  0.943537  0.372152  3.918258\n"
     ]
    }
   ],
   "source": [
    "tabelafinal.sort_values(\"recall\", axis = 0, ascending = False,\n",
    "                 inplace = True, na_position ='last')\n",
    "print(tabelafinal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aaff25e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
