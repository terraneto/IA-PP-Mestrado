{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c82564aa",
   "metadata": {},
   "source": [
    "# Treinamentos de Detecção de Anomalias para geração de matriz de confusão com exclusão de extremos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97204ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [algoritmo, contaminacao, acuracia, precisao, recall, fn, fp]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, roc_auc_score\n",
    "from sklearn.metrics import f1_score,accuracy_score,precision_score,recall_score\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "tabelafinal = pd.DataFrame(columns=['algoritmo','contaminacao','acuracia','precisao','recall','fn','fp'])\n",
    "print(tabelafinal)\n",
    "\n",
    "def get_confusion_matrix(reais, preditos, labels):\n",
    "    \"\"\"\n",
    "    Uma função que retorna a matriz de confusão para uma classificação binária\n",
    "    \n",
    "    Args:\n",
    "        reais (list): lista de valores reais\n",
    "        preditos (list): lista de valores preditos pelo modelos\n",
    "        labels (list): lista de labels a serem avaliados.\n",
    "            É importante que ela esteja presente, pois usaremos ela para entender\n",
    "            quem é a classe positiva e quem é a classe negativa\n",
    "    \n",
    "    Returns:\n",
    "        Um numpy.array, no formato:\n",
    "            numpy.array([\n",
    "                [ tp, fp ],\n",
    "                [ fn, tn ]\n",
    "            ])\n",
    "    \"\"\"\n",
    "    # não implementado\n",
    "    if len(labels) > 2:\n",
    "        return None\n",
    "\n",
    "    if len(reais) != len(preditos):\n",
    "        return None\n",
    "    \n",
    "    # considerando a primeira classe como a positiva, e a segunda a negativa\n",
    "    true_class = labels[0]\n",
    "    negative_class = labels[1]\n",
    "\n",
    "    # valores preditos corretamente\n",
    "    tp = 0\n",
    "    tn = 0\n",
    "    \n",
    "    # valores preditos incorretamente\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "    \n",
    "    for (indice, v_real) in enumerate(reais):\n",
    "        v_predito = preditos[indice]\n",
    "\n",
    "        # se trata de um valor real da classe positiva\n",
    "        if v_real == true_class:\n",
    "            tp += 1 if v_predito == v_real else 0\n",
    "            fp += 1 if v_predito != v_real else 0\n",
    "        else:\n",
    "            tn += 1 if v_predito == v_real else 0\n",
    "            fn += 1 if v_predito != v_real else 0\n",
    "    \n",
    "    return np.array([\n",
    "        # valores da classe positiva\n",
    "        [ tp, fp ],\n",
    "        # valores da classe negativa\n",
    "        [ fn, tn ]\n",
    "       \n",
    "    ])\n",
    "\n",
    "def acuracia(mc):\n",
    "  tp = mc[0,0]\n",
    "  tn = mc[1,1]\n",
    "  fp = mc[0,1]\n",
    "  fn = mc[1,0]\n",
    "  acuracia = (tp+tn)/(tp+fp+tn+fn)\n",
    "  return acuracia\n",
    "\n",
    "def recall(mc): \n",
    "  tp = mc[0,0]\n",
    "  fn = mc[1,0]\n",
    "  return tp/(tp+fn)\n",
    "\n",
    "def precisao(mc):\n",
    "  tp = mc[0,0]\n",
    "  fp = mc[0,1]\n",
    "  return tp/(tp+fp) \n",
    "\n",
    "def fscore(precisao,recall):\n",
    "  return 2*((precisao*recall)/(precisao+recall))\n",
    "\n",
    "def avalia(clf_name,Y,y_train_scores,y_train_pred):\n",
    "    # Avalia e imprime os resultados\n",
    "    print(\"Avaliação do modelo \"+clf_name+\":\")\n",
    "    evaluate_print(clf_name, Y, y_train_scores)\n",
    "    mc=get_confusion_matrix(reais=Y, preditos=clf.labels_ , labels=[0,1])\n",
    "    print('Acurácia='+str(acuracia(mc)*100))   \n",
    "    print('Precisão='+str(precisao(mc)*100))\n",
    "    print('Recall='+str(recall(mc)*100))\n",
    "    print('Falso Positivo='+str(mc[0,1]))\n",
    "    print('Falso Negativo='+str(mc[1,0]))\n",
    "    print('F1-score='+str(f1_score(Y,y_train_pred)*100))\n",
    "    print('ROC='+str(roc_auc_score(Y,y_train_scores)))\n",
    "\n",
    "def gera_matriz_de_confusao(Y,y_train_pred,clf_name):\n",
    "    cm = confusion_matrix(Y,y_train_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Normal','Anomalia'])\n",
    "    disp.plot(cmap=plt.cm.Blues)\n",
    "    disp.ax_.set(title='Matriz de Confusão do '+clf_name,xlabel='Valores preditos', ylabel='Valores reais')\n",
    "    plt.show()\n",
    "      \n",
    "def calcula_anomalias(clf_name,parametros):\n",
    "    menorfn=len(X)\n",
    "    melhoracuracia=0\n",
    "    mcont=0\n",
    "    contamination=0.01\n",
    "    while contamination<0.11:\n",
    "        funcao=clf_name+'('+parametros+'contamination='+str(contamination)+')'\n",
    "        clf = eval(funcao)\n",
    "        clf.fit(X)\n",
    "        mc=get_confusion_matrix(reais=Y, preditos=clf.labels_ , labels=[0,1])\n",
    "        ac=acuracia(mc)\n",
    "        fn=mc[1,0]   # inverti\n",
    "        if fn<menorfn:\n",
    "           mcont=contamination\n",
    "           menorfn=fn\n",
    "           melhoracuracia=ac\n",
    "        else:\n",
    "            if fn==menorfn:\n",
    "                if ac>melhoracuracia:\n",
    "                   mcont=contamination\n",
    "                   menorfn=fn\n",
    "                   melhoracuracia=ac                \n",
    "        contamination=contamination+0.01\n",
    "    contamination=mcont\n",
    "    print('Contaminação utilizada='+str(contamination))\n",
    "    clf = eval(funcao)\n",
    "    clf.fit(X)\n",
    "    return clf\n",
    "\n",
    "def grava_avaliacao(clf_name,Y,y_train_scores,y_train_pred,contamination):\n",
    "    # Avalia e imprime os resultados\n",
    "    print(\"Avaliação do modelo \"+clf_name+\":\")\n",
    "    evaluate_print(clf_name, Y, y_train_scores)\n",
    "    mc=get_confusion_matrix(reais=Y, preditos=clf.labels_ , labels=[0,1])\n",
    "    ac=round(acuracia(mc)*100,2)\n",
    "    print('Acurácia='+str(ac))   \n",
    "    pc=round(precisao(mc)*100,2)\n",
    "    print('Precisão='+str(pc))\n",
    "    rc=round(recall(mc)*100,2)\n",
    "    print('Recall='+str(rc))\n",
    "    fn=mc[1,0] \n",
    "    fp=mc[0,1]\n",
    "    print('Falso Negativo='+str(fn))\n",
    "    print('Falso Positivo='+str(fp))\n",
    "    tabelafinal.loc[len(tabelafinal.index)] = [clf_name,contamination,ac,pc,rc,fn,fp] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e6c63a",
   "metadata": {},
   "source": [
    "# Carrega dados de arquivo CSV  \n",
    "Separando catmat_id= 445485 -> Descrição:'ÁGUA MINERAL NATURAL, TIPO SEM GÁS MATERIAL EMBALAGEM PLÁSTICO TIPO EMBALAGEM \n",
    "RETORNÁVEL', Grupo: '89', SUBSISTÊNCIA Classe: '8960', BEBIDAS NÃO ALCOÓLICAS PDM: '19555', ÁGUA MINERAL NATURAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93956583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      data  quantidade  valor_unitario  anomalia\n",
      "0      1.0         420           12.00         0\n",
      "1      2.0       28000            5.88         1\n",
      "2     15.0         360            7.70         0\n",
      "3     15.0         120            7.70         0\n",
      "4     16.0        2985            4.20         0\n",
      "..     ...         ...             ...       ...\n",
      "389  419.0        1440           11.37         0\n",
      "390  419.0        4608            0.62         1\n",
      "391   37.0        1440           10.58         0\n",
      "392   37.0        4608            0.54         1\n",
      "393   95.0          10           20.00         1\n",
      "\n",
      "[394 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "def load_itens(path):\n",
    "    csv_path = os.path.join(path,\"aguatabela2.csv\")\n",
    "    return pd.read_csv(csv_path)\n",
    "\n",
    "df=load_itens(\".\")\n",
    "#df = df.drop(['data'],axis=1)\n",
    "print(df)\n",
    "dfajustado=df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a9d49c",
   "metadata": {},
   "source": [
    "# Pré-processamento retira os 2,5% menores valores e os 2,5% maiores valores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "361ecf97",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dbConnection' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m dfajuste\u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_sql(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSELECT valor_unitario FROM siasg.agua\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[43mdbConnection\u001b[49m);\n\u001b[0;32m      2\u001b[0m menor\u001b[38;5;241m=\u001b[39mdfajuste\u001b[38;5;241m.\u001b[39mquantile(\u001b[38;5;241m0.025\u001b[39m)\n\u001b[0;32m      3\u001b[0m maior\u001b[38;5;241m=\u001b[39mdfajuste\u001b[38;5;241m.\u001b[39mquantile(\u001b[38;5;241m0.975\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dbConnection' is not defined"
     ]
    }
   ],
   "source": [
    "dfajuste= pd.read_sql('SELECT valor_unitario FROM siasg.agua', dbConnection);\n",
    "menor=dfajuste.quantile(0.025)\n",
    "maior=dfajuste.quantile(0.975)\n",
    "print(menor[0])\n",
    "print(maior[0])\n",
    "dfajuste2= pd.read_sql('SELECT quantidade FROM siasg.agua', dbConnection);\n",
    "menorqtd=dfajuste2.quantile(0.05)\n",
    "maiorqtd=dfajuste2.quantile(0.95)\n",
    "print(menorqtd[0])\n",
    "print(maiorqtd[0])\n",
    "dfajustado=df.loc[df[\"valor_unitario\"] > menor[0]]\n",
    "dfajustado=dfajustado.loc[dfajustado[\"valor_unitario\"] < maior[0]]\n",
    "dfajustado=dfajustado.loc[dfajustado[\"quantidade\"] > menorqtd[0]]\n",
    "dfajustado=dfajustado.loc[dfajustado[\"quantidade\"] < maiorqtd[0]]\n",
    "print(dfajustado)\n",
    "print(dfajustado.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da98c6c0",
   "metadata": {},
   "source": [
    "# Separação do Label dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5eb1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = dfajustado.iloc[:, :-1]\n",
    "Y = dfajustado.iloc[:, -1]\n",
    "print(X)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b797dba",
   "metadata": {},
   "source": [
    "# Pré-processamento normalização dos dados (min-max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3c80e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"Example of using SUOD for accelerating outlier detection\n",
    "\"\"\"\n",
    "# Author: Yue Zhao <zhaoy@cmu.edu>\n",
    "# License: BSD 2 clause\n",
    "\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from pyod.models.suod import SUOD\n",
    "from pyod.models.lof import LOF\n",
    "from pyod.models.iforest import IForest\n",
    "from pyod.models.knn import KNN\n",
    "from pyod.models.pca import PCA\n",
    "from pyod.models.hbos import HBOS\n",
    "from pyod.models.ecod import ECOD\n",
    "from pyod.models.copod import COPOD\n",
    "from pyod.models.ocsvm import OCSVM\n",
    "from pyod.utils.utility import standardizer\n",
    "from pyod.utils.data import generate_data\n",
    "from pyod.utils.data import evaluate_print\n",
    "from pyod.utils.example import visualize\n",
    "\n",
    "X = dfajustado\n",
    "contamination=0.15\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8439b462",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyod.models.pca import PCA\n",
    "# train PCA detector\n",
    "clf_name = 'PCA'\n",
    "#clf = PCA(n_components=3,n_selected_components=2,contamination=contamination)\n",
    "#clf.fit(X)\n",
    "clf=calcula_anomalias('PCA','n_components=3,n_selected_components=2,')\n",
    "avalia(clf_name,Y,clf.decision_scores_,clf.labels_)\n",
    "print('')\n",
    "gera_matriz_de_confusao(Y,clf.labels_ ,clf_name)\n",
    "\n",
    "grava_avaliacao(clf_name,Y,clf.decision_scores_,clf.labels_,round(contamination,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5c6a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyod.models.ocsvm import OCSVM\n",
    "# train OCSVM detector\n",
    "clf_name = 'OCSVM'\n",
    "\n",
    "clf=calcula_anomalias(clf_name,'')\n",
    "avalia(clf_name,Y,clf.decision_scores_,clf.labels_)\n",
    "print('')\n",
    "gera_matriz_de_confusao(Y,clf.labels_ ,clf_name)\n",
    "grava_avaliacao(clf_name,Y,clf.decision_scores_,clf.labels_,round(contamination,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbbec453",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pyod.models.lof import LOF\n",
    "# train LOF detector\n",
    "clf_name = 'LOF'\n",
    "itens = len(X)/2\n",
    "vizinhos=2\n",
    "macuracia=0\n",
    "nv=2\n",
    "while vizinhos<itens: \n",
    "    clf = LOF(n_neighbors=vizinhos,contamination=contamination)\n",
    "    clf.fit(X)\n",
    "    y_train_pred = clf.labels_  # binary labels (0: inliers, 1: outliers)        \n",
    "    ac=accuracy_score(Y,y_train_pred)\n",
    "    if ac>macuracia:\n",
    "        nv=vizinhos\n",
    "        macuracia=ac\n",
    "    vizinhos=vizinhos+1\n",
    "\n",
    "print(nv)    \n",
    "\n",
    "clf=calcula_anomalias(clf_name,'n_neighbors='+str(nv)+',')\n",
    "avalia(clf_name,Y,clf.decision_scores_,clf.labels_)\n",
    "print('')\n",
    "gera_matriz_de_confusao(Y,clf.labels_ ,clf_name)\n",
    "grava_avaliacao(clf_name,Y,clf.decision_scores_,clf.labels_,round(contamination,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cffc8b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pyod.models.cblof import CBLOF\n",
    "# train CBLOF detector\n",
    "clf_name = 'CBLOF' \n",
    "\n",
    "clf=calcula_anomalias(clf_name,'')\n",
    "avalia(clf_name,Y,clf.decision_scores_,clf.labels_)\n",
    "print('')\n",
    "gera_matriz_de_confusao(Y,clf.labels_ ,clf_name)\n",
    "grava_avaliacao(clf_name,Y,clf.decision_scores_,clf.labels_,round(contamination,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28d32e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pyod.models.cof import COF\n",
    "# train COF detector\n",
    "clf_name = 'COF' \n",
    "clf=calcula_anomalias(clf_name,'')\n",
    "avalia(clf_name,Y,clf.decision_scores_,clf.labels_)\n",
    "print('')\n",
    "gera_matriz_de_confusao(Y,clf.labels_ ,clf_name)\n",
    "grava_avaliacao(clf_name,Y,clf.decision_scores_,clf.labels_,round(contamination,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77476430",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyod.models.hbos import HBOS\n",
    "\n",
    "# train HBOS detector\n",
    "clf_name = 'HBOS'\n",
    "\n",
    "clf=calcula_anomalias(clf_name,'n_bins=35, alpha=contamination,')\n",
    "avalia(clf_name,Y,clf.decision_scores_,clf.labels_)\n",
    "print('')\n",
    "gera_matriz_de_confusao(Y,clf.labels_ ,clf_name)\n",
    "grava_avaliacao(clf_name,Y,clf.decision_scores_,clf.labels_,round(contamination,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a8023e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyod.models.knn import KNN\n",
    "# train KNN detector\n",
    "clf_name = 'KNN'\n",
    "clf=calcula_anomalias(clf_name,'n_neighbors=35,')\n",
    "\n",
    "avalia(clf_name,Y,clf.decision_scores_,clf.labels_)\n",
    "print('')\n",
    "gera_matriz_de_confusao(Y,clf.labels_ ,clf_name)\n",
    "grava_avaliacao(clf_name,Y,clf.decision_scores_,clf.labels_,round(contamination,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799c60cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyod.models.sod import SOD\n",
    "# train SOD detector\n",
    "clf_name = 'SOD' \n",
    "clf=calcula_anomalias(clf_name,'')\n",
    "\n",
    "avalia(clf_name,Y,clf.decision_scores_,clf.labels_)\n",
    "print('')\n",
    "gera_matriz_de_confusao(Y,clf.labels_ ,clf_name)\n",
    "grava_avaliacao(clf_name,Y,clf.decision_scores_,clf.labels_,round(contamination,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17260990",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyod.models.copod import COPOD\n",
    "# train COPOD detector\n",
    "clf_name = 'COPOD'\n",
    "clf=calcula_anomalias(clf_name,'')\n",
    "\n",
    "avalia(clf_name,Y,clf.decision_scores_,clf.labels_)\n",
    "print('')\n",
    "gera_matriz_de_confusao(Y,clf.labels_ ,clf_name)\n",
    "grava_avaliacao(clf_name,Y,clf.decision_scores_,clf.labels_,round(contamination,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739b504c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyod.models.ecod import ECOD\n",
    "# train ECOD detector\n",
    "clf_name = 'ECOD'\n",
    "clf=calcula_anomalias(clf_name,'')\n",
    "\n",
    "avalia(clf_name,Y,clf.decision_scores_,clf.labels_)\n",
    "print('')\n",
    "gera_matriz_de_confusao(Y,clf.labels_ ,clf_name)\n",
    "grava_avaliacao(clf_name,Y,clf.decision_scores_,clf.labels_,round(contamination,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8017695",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyod.models.iforest import IForest\n",
    "# train IForest detector\n",
    "clf_name = 'IForest'\n",
    "itens = len(X)\n",
    "estimadores = len(X)//10\n",
    "if estimadores<2: estimadores=2\n",
    "\n",
    "clf=calcula_anomalias(clf_name,'n_estimators=estimadores,')\n",
    "avalia(clf_name,Y,clf.decision_scores_,clf.labels_)\n",
    "print('')\n",
    "gera_matriz_de_confusao(Y,clf.labels_ ,clf_name)\n",
    "grava_avaliacao(clf_name,Y,clf.decision_scores_,clf.labels_,round(contamination,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692fa7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyod.models.loda import LODA\n",
    "# train LODA detector\n",
    "clf_name = 'LODA' \n",
    "clf=calcula_anomalias(clf_name,'')\n",
    "avalia(clf_name,Y,clf.decision_scores_,clf.labels_)\n",
    "print('')\n",
    "gera_matriz_de_confusao(Y,clf.labels_ ,clf_name)\n",
    "grava_avaliacao(clf_name,Y,clf.decision_scores_,clf.labels_,round(contamination,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09e487e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyod.models.deep_svdd import DeepSVDD\n",
    "# train DeepSVDD detector\n",
    "clf_name = 'DeepSVDD'\n",
    "clf=calcula_anomalias(clf_name,'verbose=0,preprocessing=True,')\n",
    "\n",
    "avalia(clf_name,Y,clf.decision_scores_,clf.labels_)\n",
    "print('')\n",
    "gera_matriz_de_confusao(Y,clf.labels_ ,clf_name)\n",
    "grava_avaliacao(clf_name,Y,clf.decision_scores_,clf.labels_,round(contamination,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1cdbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyod.models.gmm import GMM\n",
    "# train GMM detector\n",
    "clf_name = 'GMM' \n",
    "clf=calcula_anomalias(clf_name,'')\n",
    "avalia(clf_name,Y,clf.decision_scores_,clf.labels_)\n",
    "print('')\n",
    "gera_matriz_de_confusao(Y,clf.labels_ ,clf_name)\n",
    "grava_avaliacao(clf_name,Y,clf.decision_scores_,clf.labels_,round(contamination,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6f667b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tabelafinal.sort_values(\"acuracia\", axis = 0, ascending = False,\n",
    "                 inplace = True, na_position ='last')\n",
    "print(tabelafinal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e157144",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
