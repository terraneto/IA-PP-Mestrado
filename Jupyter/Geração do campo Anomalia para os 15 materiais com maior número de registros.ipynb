{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "600a16c5-09ff-4349-bfa4-64c592d2cda2",
   "metadata": {},
   "source": [
    "# Geração do campo Anomalia para os 15 materiais com maior número de registros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703d4e98-d9b8-4961-a1ad-375319198424",
   "metadata": {},
   "source": [
    "Importação das bibliotecas necessárias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbd2c454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usando Python 3.11\n",
    "#Importa a biblioteca pandas\n",
    "import pandas as pd \n",
    "\n",
    "#Importa a biblioteca os \n",
    "import os \n",
    "\n",
    "#Importa as blibliotecas do Sklearn\n",
    "#from sklearn.compose import ColumnTransformer \n",
    "#from sklearn.pipeline import Pipeline \n",
    "#from sklearn.preprocessing import StandardScaler,PolynomialFeatures,OneHotEncoder,OrdinalEncoder \n",
    "\n",
    "#Importa a biblioteca Numpy\n",
    "import numpy as np \n",
    "\n",
    "#importa bibliotecas snorkel \n",
    "import snorkel \n",
    "from snorkel.labeling import labeling_function \n",
    "from snorkel.labeling import PandasLFApplier\n",
    "from snorkel.labeling.apply.dask import DaskLFApplier\n",
    "from snorkel.labeling.apply.dask import PandasParallelLFApplier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc395b7e-bac3-47e1-8a6d-19b820d858dd",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "Define funções de busca dos dados no MySQL e de criação de csv com os dados selecionados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "350f6315",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy import text\n",
    "\n",
    "def busca_dados_mysql(id_material):\n",
    "    if os.path.exists('itens.csv'):\n",
    "        os.remove('itens.csv')\n",
    "    sqlEngine       = create_engine('mysql+pymysql://siasg:siasg@192.168.2.135/siasg', pool_recycle=3600)\n",
    "    dbConnection    = sqlEngine.connect()\n",
    "    meusql=\"SELECT * FROM siasg.itens where catmat_id=\"+str(id_material)\n",
    "    df = pd.read_sql(text(meusql), dbConnection);\n",
    "    filtro  = df['valor_unitario'] > 0\n",
    "    df = df[filtro]\n",
    "    df.to_csv('itens.csv',index=False)\n",
    "    \n",
    "def load_itens(path):\n",
    "    csv_path = os.path.join(path,\"itens.csv\")\n",
    "    return pd.read_csv(csv_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f8ea5e-33c2-4691-b5b4-5d5bd88ade9c",
   "metadata": {},
   "source": [
    "Busca os dados do material MICROCOMPUTADOR - Catmat = 469793"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a02c1c6a-49bb-4a73-bca1-d1b3ba2aa6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "from urllib.request import urlopen\n",
    "from urllib.error import URLError, HTTPError\n",
    "import pymysql\n",
    "import datetime\n",
    "import json\n",
    "from sqlalchemy.dialects.mysql import insert\n",
    "import pandas as pd\n",
    "sqlEngine       = create_engine('mysql+pymysql://siasg:siasg@192.168.2.135/siasg', pool_recycle=3600)\n",
    "dbConnection    = sqlEngine.connect()\n",
    "itens = pd.read_sql(\"SELECT * from siasg.itens\", dbConnection);\n",
    "\n",
    "maioresitens = pd.read_sql(\"SELECT catmat_id, count(*) from siasg.itens where valor_unitario>0 and catmat_id!=0 group by catmat_id order by count(*) desc\", dbConnection);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8066297e-11e7-40e8-aaa9-83454175ffa2",
   "metadata": {},
   "source": [
    "Definição das Funções de rotulagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb614a19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47391/47391 [00:00<00:00, 77137.84it/s]\n",
      "INFO:root:Computing O...\n",
      "INFO:root:Estimating \\mu...\n",
      "  0%|          | 0/500 [00:00<?, ?epoch/s]INFO:root:[0 epochs]: TRAIN:[loss=0.393]\n",
      "INFO:root:[100 epochs]: TRAIN:[loss=0.000]\n",
      " 36%|███▌      | 180/500 [00:00<00:00, 1794.45epoch/s]INFO:root:[200 epochs]: TRAIN:[loss=0.000]\n",
      "INFO:root:[300 epochs]: TRAIN:[loss=0.000]\n",
      " 75%|███████▌  | 375/500 [00:00<00:00, 1885.57epoch/s]INFO:root:[400 epochs]: TRAIN:[loss=0.000]\n",
      "100%|██████████| 500/500 [00:00<00:00, 1904.94epoch/s]\n",
      "INFO:root:Finished Training\n",
      "100%|██████████| 17409/17409 [00:00<00:00, 71438.98it/s]\n",
      "INFO:root:Computing O...\n",
      "INFO:root:Estimating \\mu...\n",
      "  0%|          | 0/500 [00:00<?, ?epoch/s]INFO:root:[0 epochs]: TRAIN:[loss=0.394]\n",
      "INFO:root:[100 epochs]: TRAIN:[loss=0.000]\n",
      " 40%|████      | 200/500 [00:00<00:00, 1997.27epoch/s]INFO:root:[200 epochs]: TRAIN:[loss=0.000]\n",
      "INFO:root:[300 epochs]: TRAIN:[loss=0.000]\n",
      "INFO:root:[400 epochs]: TRAIN:[loss=0.000]\n",
      "100%|██████████| 500/500 [00:00<00:00, 2046.84epoch/s]\n",
      "INFO:root:Finished Training\n",
      "100%|██████████| 741/741 [00:00<00:00, 58443.73it/s]\n",
      "INFO:root:Computing O...\n",
      "INFO:root:Estimating \\mu...\n",
      "  0%|          | 0/500 [00:00<?, ?epoch/s]INFO:root:[0 epochs]: TRAIN:[loss=0.390]\n",
      "INFO:root:[100 epochs]: TRAIN:[loss=0.000]\n",
      " 39%|███▊      | 193/500 [00:00<00:00, 1926.89epoch/s]INFO:root:[200 epochs]: TRAIN:[loss=0.000]\n",
      "INFO:root:[300 epochs]: TRAIN:[loss=0.000]\n",
      " 78%|███████▊  | 392/500 [00:00<00:00, 1955.58epoch/s]INFO:root:[400 epochs]: TRAIN:[loss=0.000]\n",
      "100%|██████████| 500/500 [00:00<00:00, 1971.76epoch/s]\n",
      "INFO:root:Finished Training\n",
      "100%|██████████| 431/431 [00:00<00:00, 28343.00it/s]\n",
      "INFO:root:Computing O...\n",
      "INFO:root:Estimating \\mu...\n",
      "  0%|          | 0/500 [00:00<?, ?epoch/s]INFO:root:[0 epochs]: TRAIN:[loss=0.407]\n",
      "INFO:root:[100 epochs]: TRAIN:[loss=0.000]\n",
      "INFO:root:[200 epochs]: TRAIN:[loss=0.000]\n",
      " 41%|████      | 203/500 [00:00<00:00, 2016.45epoch/s]INFO:root:[300 epochs]: TRAIN:[loss=0.000]\n",
      "INFO:root:[400 epochs]: TRAIN:[loss=0.000]\n",
      "100%|██████████| 500/500 [00:00<00:00, 1887.60epoch/s]\n",
      "INFO:root:Finished Training\n",
      "100%|██████████| 384/384 [00:00<00:00, 56725.70it/s]\n",
      "INFO:root:Computing O...\n",
      "INFO:root:Estimating \\mu...\n",
      "  0%|          | 0/500 [00:00<?, ?epoch/s]INFO:root:[0 epochs]: TRAIN:[loss=0.386]\n",
      "INFO:root:[100 epochs]: TRAIN:[loss=0.000]\n",
      " 37%|███▋      | 186/500 [00:00<00:00, 1857.46epoch/s]INFO:root:[200 epochs]: TRAIN:[loss=0.000]\n",
      "INFO:root:[300 epochs]: TRAIN:[loss=0.000]\n",
      " 78%|███████▊  | 389/500 [00:00<00:00, 1958.79epoch/s]INFO:root:[400 epochs]: TRAIN:[loss=0.000]\n",
      "100%|██████████| 500/500 [00:00<00:00, 1952.27epoch/s]\n",
      "INFO:root:Finished Training\n",
      "100%|██████████| 357/357 [00:00<00:00, 50918.71it/s]\n",
      "INFO:root:Computing O...\n",
      "INFO:root:Estimating \\mu...\n",
      "  0%|          | 0/500 [00:00<?, ?epoch/s]INFO:root:[0 epochs]: TRAIN:[loss=0.391]\n",
      "INFO:root:[100 epochs]: TRAIN:[loss=0.000]\n",
      " 33%|███▎      | 166/500 [00:00<00:00, 1649.75epoch/s]INFO:root:[200 epochs]: TRAIN:[loss=0.000]\n",
      "INFO:root:[300 epochs]: TRAIN:[loss=0.000]\n",
      " 72%|███████▏  | 360/500 [00:00<00:00, 1819.42epoch/s]INFO:root:[400 epochs]: TRAIN:[loss=0.000]\n",
      "100%|██████████| 500/500 [00:00<00:00, 1837.34epoch/s]\n",
      "INFO:root:Finished Training\n",
      "100%|██████████| 347/347 [00:00<00:00, 57819.14it/s]\n",
      "INFO:root:Computing O...\n",
      "INFO:root:Estimating \\mu...\n",
      "  0%|          | 0/500 [00:00<?, ?epoch/s]INFO:root:[0 epochs]: TRAIN:[loss=0.383]\n",
      "INFO:root:[100 epochs]: TRAIN:[loss=0.000]\n",
      " 39%|███▊      | 193/500 [00:00<00:00, 1912.59epoch/s]INFO:root:[200 epochs]: TRAIN:[loss=0.000]\n",
      "INFO:root:[300 epochs]: TRAIN:[loss=0.000]\n",
      " 79%|███████▊  | 393/500 [00:00<00:00, 1954.60epoch/s]INFO:root:[400 epochs]: TRAIN:[loss=0.000]\n",
      "100%|██████████| 500/500 [00:00<00:00, 1950.71epoch/s]\n",
      "INFO:root:Finished Training\n",
      "100%|██████████| 277/277 [00:00<00:00, 38903.77it/s]\n",
      "INFO:root:Computing O...\n",
      "INFO:root:Estimating \\mu...\n",
      "  0%|          | 0/500 [00:00<?, ?epoch/s]INFO:root:[0 epochs]: TRAIN:[loss=0.000]\n",
      "INFO:root:[100 epochs]: TRAIN:[loss=0.000]\n",
      " 39%|███▉      | 194/500 [00:00<00:00, 1935.31epoch/s]INFO:root:[200 epochs]: TRAIN:[loss=0.000]\n",
      "INFO:root:[300 epochs]: TRAIN:[loss=0.000]\n",
      " 78%|███████▊  | 388/500 [00:00<00:00, 1909.32epoch/s]INFO:root:[400 epochs]: TRAIN:[loss=0.000]\n",
      "100%|██████████| 500/500 [00:00<00:00, 1911.65epoch/s]\n",
      "INFO:root:Finished Training\n",
      "100%|██████████| 209/209 [00:00<?, ?it/s]\n",
      "INFO:root:Computing O...\n",
      "INFO:root:Estimating \\mu...\n",
      "  0%|          | 0/500 [00:00<?, ?epoch/s]INFO:root:[0 epochs]: TRAIN:[loss=0.379]\n",
      "INFO:root:[100 epochs]: TRAIN:[loss=0.000]\n",
      " 33%|███▎      | 165/500 [00:00<00:00, 1647.61epoch/s]INFO:root:[200 epochs]: TRAIN:[loss=0.000]\n",
      "INFO:root:[300 epochs]: TRAIN:[loss=0.000]\n",
      " 71%|███████   | 354/500 [00:00<00:00, 1780.10epoch/s]INFO:root:[400 epochs]: TRAIN:[loss=0.000]\n",
      "100%|██████████| 500/500 [00:00<00:00, 1879.47epoch/s]\n",
      "INFO:root:Finished Training\n",
      "100%|██████████| 205/205 [00:00<00:00, 37135.37it/s]\n",
      "INFO:root:Computing O...\n",
      "INFO:root:Estimating \\mu...\n",
      "  0%|          | 0/500 [00:00<?, ?epoch/s]INFO:root:[0 epochs]: TRAIN:[loss=0.366]\n",
      "INFO:root:[100 epochs]: TRAIN:[loss=0.000]\n",
      " 39%|███▉      | 197/500 [00:00<00:00, 1952.59epoch/s]INFO:root:[200 epochs]: TRAIN:[loss=0.000]\n",
      "INFO:root:[300 epochs]: TRAIN:[loss=0.000]\n",
      " 80%|███████▉  | 399/500 [00:00<00:00, 1988.84epoch/s]INFO:root:[400 epochs]: TRAIN:[loss=0.000]\n",
      "100%|██████████| 500/500 [00:00<00:00, 1994.98epoch/s]\n",
      "INFO:root:Finished Training\n",
      "100%|██████████| 190/190 [00:00<00:00, 181778.69it/s]\n",
      "INFO:root:Computing O...\n",
      "INFO:root:Estimating \\mu...\n",
      "  0%|          | 0/500 [00:00<?, ?epoch/s]INFO:root:[0 epochs]: TRAIN:[loss=0.387]\n",
      "INFO:root:[100 epochs]: TRAIN:[loss=0.000]\n",
      " 31%|███       | 154/500 [00:00<00:00, 1532.18epoch/s]INFO:root:[200 epochs]: TRAIN:[loss=0.000]\n",
      "INFO:root:[300 epochs]: TRAIN:[loss=0.000]\n",
      " 64%|██████▍   | 319/500 [00:00<00:00, 1593.19epoch/s]INFO:root:[400 epochs]: TRAIN:[loss=0.000]\n",
      "100%|██████████| 500/500 [00:00<00:00, 1703.43epoch/s]\n",
      "INFO:root:Finished Training\n",
      "100%|██████████| 159/159 [00:00<00:00, 60914.72it/s]\n",
      "INFO:root:Computing O...\n",
      "INFO:root:Estimating \\mu...\n",
      "  0%|          | 0/500 [00:00<?, ?epoch/s]INFO:root:[0 epochs]: TRAIN:[loss=0.371]\n",
      "INFO:root:[100 epochs]: TRAIN:[loss=0.000]\n",
      " 38%|███▊      | 188/500 [00:00<00:00, 1864.19epoch/s]INFO:root:[200 epochs]: TRAIN:[loss=0.000]\n",
      "INFO:root:[300 epochs]: TRAIN:[loss=0.000]\n",
      " 75%|███████▌  | 377/500 [00:00<00:00, 1873.39epoch/s]INFO:root:[400 epochs]: TRAIN:[loss=0.000]\n",
      "100%|██████████| 500/500 [00:00<00:00, 1870.48epoch/s]\n",
      "INFO:root:Finished Training\n",
      "100%|██████████| 158/158 [00:00<00:00, 65322.82it/s]\n",
      "INFO:root:Computing O...\n",
      "INFO:root:Estimating \\mu...\n",
      "  0%|          | 0/500 [00:00<?, ?epoch/s]INFO:root:[0 epochs]: TRAIN:[loss=0.387]\n",
      "INFO:root:[100 epochs]: TRAIN:[loss=0.000]\n",
      " 24%|██▍       | 121/500 [00:00<00:00, 1055.26epoch/s]INFO:root:[200 epochs]: TRAIN:[loss=0.000]\n",
      " 56%|█████▌    | 278/500 [00:00<00:00, 1340.26epoch/s]INFO:root:[300 epochs]: TRAIN:[loss=0.000]\n",
      "INFO:root:[400 epochs]: TRAIN:[loss=0.000]\n",
      "100%|██████████| 500/500 [00:00<00:00, 1384.26epoch/s]\n",
      "INFO:root:Finished Training\n",
      "100%|██████████| 155/155 [00:00<00:00, 63382.77it/s]\n",
      "INFO:root:Computing O...\n",
      "INFO:root:Estimating \\mu...\n",
      "  0%|          | 0/500 [00:00<?, ?epoch/s]INFO:root:[0 epochs]: TRAIN:[loss=0.377]\n",
      "INFO:root:[100 epochs]: TRAIN:[loss=0.000]\n",
      " 37%|███▋      | 183/500 [00:00<00:00, 1818.80epoch/s]INFO:root:[200 epochs]: TRAIN:[loss=0.000]\n",
      "INFO:root:[300 epochs]: TRAIN:[loss=0.000]\n",
      " 77%|███████▋  | 387/500 [00:00<00:00, 1943.34epoch/s]INFO:root:[400 epochs]: TRAIN:[loss=0.000]\n",
      "100%|██████████| 500/500 [00:00<00:00, 1809.03epoch/s]\n",
      "INFO:root:Finished Training\n",
      "100%|██████████| 154/154 [00:00<00:00, 45458.71it/s]\n",
      "INFO:root:Computing O...\n",
      "INFO:root:Estimating \\mu...\n",
      "  0%|          | 0/500 [00:00<?, ?epoch/s]INFO:root:[0 epochs]: TRAIN:[loss=0.346]\n",
      "INFO:root:[100 epochs]: TRAIN:[loss=0.000]\n",
      " 39%|███▉      | 196/500 [00:00<00:00, 1951.97epoch/s]INFO:root:[200 epochs]: TRAIN:[loss=0.000]\n",
      "INFO:root:[300 epochs]: TRAIN:[loss=0.000]\n",
      " 80%|███████▉  | 399/500 [00:00<00:00, 1990.31epoch/s]INFO:root:[400 epochs]: TRAIN:[loss=0.000]\n",
      "100%|██████████| 500/500 [00:00<00:00, 1866.99epoch/s]\n",
      "INFO:root:Finished Training\n",
      "100%|██████████| 152/152 [00:00<00:00, 48871.92it/s]\n",
      "INFO:root:Computing O...\n",
      "INFO:root:Estimating \\mu...\n",
      "  0%|          | 0/500 [00:00<?, ?epoch/s]INFO:root:[0 epochs]: TRAIN:[loss=0.376]\n",
      "INFO:root:[100 epochs]: TRAIN:[loss=0.000]\n",
      "INFO:root:[200 epochs]: TRAIN:[loss=0.000]\n",
      " 42%|████▏     | 209/500 [00:00<00:00, 1824.56epoch/s]INFO:root:[300 epochs]: TRAIN:[loss=0.000]\n",
      " 79%|███████▊  | 393/500 [00:00<00:00, 1819.31epoch/s]INFO:root:[400 epochs]: TRAIN:[loss=0.000]\n",
      "100%|██████████| 500/500 [00:00<00:00, 1586.07epoch/s]\n",
      "INFO:root:Finished Training\n",
      "100%|██████████| 151/151 [00:00<00:00, 43430.01it/s]\n",
      "INFO:root:Computing O...\n",
      "INFO:root:Estimating \\mu...\n",
      "  0%|          | 0/500 [00:00<?, ?epoch/s]INFO:root:[0 epochs]: TRAIN:[loss=0.385]\n",
      "INFO:root:[100 epochs]: TRAIN:[loss=0.000]\n",
      " 29%|██▉       | 144/500 [00:00<00:00, 1434.85epoch/s]INFO:root:[200 epochs]: TRAIN:[loss=0.000]\n",
      "INFO:root:[300 epochs]: TRAIN:[loss=0.000]\n",
      " 68%|██████▊   | 341/500 [00:00<00:00, 1704.28epoch/s]INFO:root:[400 epochs]: TRAIN:[loss=0.000]\n",
      "100%|██████████| 500/500 [00:00<00:00, 1772.97epoch/s]\n",
      "INFO:root:Finished Training\n",
      "100%|██████████| 148/148 [00:00<00:00, 73462.37it/s]\n",
      "INFO:root:Computing O...\n",
      "INFO:root:Estimating \\mu...\n",
      "  0%|          | 0/500 [00:00<?, ?epoch/s]INFO:root:[0 epochs]: TRAIN:[loss=0.384]\n",
      "INFO:root:[100 epochs]: TRAIN:[loss=0.000]\n",
      " 30%|███       | 150/500 [00:00<00:00, 1487.88epoch/s]INFO:root:[200 epochs]: TRAIN:[loss=0.000]\n",
      "INFO:root:[300 epochs]: TRAIN:[loss=0.000]\n",
      " 60%|██████    | 301/500 [00:00<00:00, 1489.07epoch/s]INFO:root:[400 epochs]: TRAIN:[loss=0.000]\n",
      "100%|██████████| 500/500 [00:00<00:00, 1554.56epoch/s]\n",
      "INFO:root:Finished Training\n"
     ]
    }
   ],
   "source": [
    "##Carrega os dados do item\n",
    "for index, row in maioresitens.iterrows():\n",
    "    catmat = row['catmat_id']\n",
    "    busca_dados_mysql(catmat)\n",
    "    df=load_itens(\".\")  \n",
    "    \n",
    "    ## Valores estatísticos de referência\n",
    "    preco_mediana = df['valor_unitario'].median()\n",
    "    preco_media = df['valor_unitario'].mean()\n",
    "    preco_maior = df['valor_unitario'].quantile(0.975)\n",
    "    preco_menor = df['valor_unitario'].min()\n",
    "    \n",
    "    quantidade_mediana = df['quantidade'].median()\n",
    "    quantidade_maior = df['quantidade'].quantile(0.975)\n",
    "    quantidade_menor = df['quantidade'].min()\n",
    "    \n",
    "    distancia_mediana = df['distancia_uasg_fornecedor'].median()\n",
    "    distancia_maior = df['distancia_uasg_fornecedor'].quantile(0.975)\n",
    "    distancia_menor = df['distancia_uasg_fornecedor'].min()\n",
    "    \n",
    "    #For clarity, we define constants to represent the class labels for normal, anomaly, and abstaining. \n",
    "    ABSTAIN=-1 \n",
    "    NORMAL=0 \n",
    "    ANOMALY=1 \n",
    "    \n",
    "    # Funções de rotulagem\n",
    "    \n",
    "    # O preço é considerado anômalo quando ele é maior que o preco_maior ou quando ele é menor que o preço_menor sem ter sido adquirido em quantidade \n",
    "    # que a maior quantidade.\n",
    "    @labeling_function() \n",
    "    def preco_anomalo(v_df): \n",
    "        preco=v_df['valor_unitario'] \n",
    "        quantidade=v_df['quantidade'] \n",
    "        return ANOMALY if ((preco > preco_maior) or ((preco < preco_menor) and ((quantidade<quantidade_maior)))) else ABSTAIN \n",
    "    \n",
    "    # A quantidade é considerada alta, quando é maior que 97,5% das quantidades adquiridas\n",
    "    @labeling_function() \n",
    "    def quantidade_alta(v_df): \n",
    "        quantidade=v_df['quantidade'] \n",
    "        #Retorna um label de anomalia se o valor é maior que 97,5% dos valores se não se ABSTAIN \n",
    "        return ANOMALY if quantidade > quantidade_maior else ABSTAIN\n",
    "    \n",
    "    # A distância entre o fornecedor e o comprador é considerada alta quando ela é maior que 97,5% das distâncias apuradas\n",
    "    @labeling_function() \n",
    "    def distancia_alta(v_df): \n",
    "        distancia=v_df['distancia_uasg_fornecedor'] \n",
    "        #Retorna um label de anomalia se o valor é maior que 97,5% dos valores se não se ABSTAIN \n",
    "        return ANOMALY if distancia > distancia_maior else ABSTAIN\n",
    "    \n",
    "    # O preço é considerado normal quando ele é menor ou igual a mediana e maior que o preco_menor ou quando o preço é maior que a mediana mas menor\n",
    "    # que o preco_maior\n",
    "    @labeling_function() \n",
    "    def normal(v_df): \n",
    "        preco=v_df['valor_unitario'] \n",
    "        quantidade=v_df['quantidade'] \n",
    "        distancia=v_df['distancia_uasg_fornecedor']\n",
    "        return NORMAL if (((preco<=preco_mediana) and (preco>preco_menor)) or ((preco>preco_mediana) and (preco<preco_maior))) else ABSTAIN                 \n",
    " \n",
    "        \n",
    "    # A função de rotulagem é criada com a junção das funções definidas acima.                     \n",
    "    lfs=[preco_anomalo,quantidade_alta,distancia_alta,normal] \n",
    "                           \n",
    "    ##Aplica as LFs ao dataset de teste obtem as rotulacoes candidatas \n",
    "    applier=PandasLFApplier(lfs=lfs) \n",
    "                           \n",
    "    dadosrotulados =applier.apply(df=df) \n",
    "    ##Salva em arquivo \n",
    "    dadosrotulados_pd=pd.DataFrame(dadosrotulados)                   \n",
    "    dadosrotulados_pd.to_csv('dadosavaliados.csv', index=False) \n",
    "    dadosrotulados=np.array(dadosrotulados_pd) \n",
    "    \n",
    "    ##Aplica o LabelModel para obter o modelo de rotulação final \n",
    "    from snorkel.labeling.model import LabelModel \n",
    "    \n",
    "    label_model=LabelModel(cardinality=2,verbose=True) \n",
    "    label_model.fit(dadosrotulados,n_epochs=500,log_freq=100,seed=123) \n",
    "    \n",
    "    ###Obtém rotulação final a partir do modelo construído \n",
    "    labels_g=label_model.predict(dadosrotulados) \n",
    "     \n",
    "    ##Salva em arquivo \n",
    "    dadosrotulados_pd=pd.DataFrame(labels_g) \n",
    "    labels_g=np.array(dadosrotulados_pd)\n",
    "    \n",
    "    df.insert(11,\"anomalia\",labels_g)\n",
    "    df.loc[df['anomalia'] == -1] = 0\n",
    "    filtro  = df['valor_unitario'] > 0\n",
    "    df = df[filtro]\n",
    "    df.to_csv(str(catmat)+'.csv', index=False)\n",
    "\n",
    "    os.remove('itens.csv')\n",
    "    os.remove('dadosavaliados.csv')\n",
    "    if index==17: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d758c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6946f063",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
