{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aaafa054",
   "metadata": {},
   "source": [
    "# Carrega arquivos mensais de Licitações da Classe 7010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da74eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "from urllib.request import urlopen\n",
    "from urllib.error import URLError, HTTPError\n",
    "import pymysql\n",
    "import datetime\n",
    "from dateutil.relativedelta import *\n",
    "from datetime import date\n",
    "import json\n",
    "from sqlalchemy.dialects.mysql import insert\n",
    "import pandas as pd\n",
    "import pandas as pd2\n",
    "\n",
    "def insert_on_duplicate(table, conn, keys, data_iter):\n",
    "    insert_stmt = insert(table.table).values(list(data_iter))\n",
    "    on_duplicate_key_stmt = insert_stmt.on_duplicate_key_update(insert_stmt.inserted)\n",
    "    conn.execute(on_duplicate_key_stmt)\n",
    "\n",
    "sqlEngine       = create_engine('mysql+pymysql://siasg:siasg@192.168.2.135/siasg', pool_recycle=3600)\n",
    "dbConnection    = sqlEngine.connect()\n",
    "\n",
    "arquivos=69\n",
    "datainicio= date(2022,8,1)\n",
    "print(datainicio)\n",
    "\n",
    "vtabela='licitacoes'\n",
    "vtabelasiasg='licitacoes'\n",
    "while(arquivos>0):\n",
    "    nomearq = '.\\json\\\\licitacoes\\\\' + vtabela + datainicio.strftime(\"%Y-%m\")+'.json'\n",
    "    print(nomearq)\n",
    "    try: \n",
    "        with open(nomearq, encoding=\"utf8\") as json_file:\n",
    "            data_json = json.loads(json_file.read())\n",
    "    except:\n",
    "        print(\"Erro na abertura do arquivo\"+nomearq)\n",
    "    try: \n",
    "        embedded = data_json[\"_embedded\"]\n",
    "        tb= embedded[vtabelasiasg]\n",
    "    except:\n",
    "        print(\"Erro na preparação do \"+nomearq)\n",
    "    try: \n",
    "        df = pd2.DataFrame.from_dict(tb, orient='columns')\n",
    "        del df['_links']\n",
    "        if 'numero_item_licitacao' in df.columns:\n",
    "           del df['numero_item_licitacao']\n",
    "        if 'codigo_do_item_no_catalogo' in df.columns:\n",
    "           del df['codigo_do_item_no_catalogo']\n",
    "    except:\n",
    "        print(\"Erro na leitura do \"+nomearq)\n",
    "    df.to_sql(vtabela, sqlEngine, if_exists='append', index=False, method=insert_on_duplicate) \n",
    "    datainicio = datainicio - relativedelta(months=1)\n",
    "    print(datainicio)\n",
    "    arquivos=arquivos-1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3c843f",
   "metadata": {},
   "source": [
    "# Carga de Itens da licitação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8430025",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "from urllib.request import urlopen\n",
    "from urllib.error import URLError, HTTPError\n",
    "import pymysql\n",
    "import datetime\n",
    "from dateutil.relativedelta import *\n",
    "from datetime import date\n",
    "import json\n",
    "from sqlalchemy.dialects.mysql import insert\n",
    "import pandas as pd\n",
    "import pandas as pd2\n",
    "\n",
    "def insert_on_duplicate(table, conn, keys, data_iter):\n",
    "    insert_stmt = insert(table.table).values(list(data_iter))\n",
    "    on_duplicate_key_stmt = insert_stmt.on_duplicate_key_update(insert_stmt.inserted)\n",
    "    conn.execute(on_duplicate_key_stmt)\n",
    "\n",
    "sqlEngine       = create_engine('mysql+pymysql://siasg:siasg@192.168.2.135/siasg', pool_recycle=3600)\n",
    "dbConnection    = sqlEngine.connect()\n",
    "\n",
    "# specify your path of directory\n",
    "path = \".\\\\json\\\\itens\"\n",
    "\n",
    "vtabela='licitacoes'\n",
    "frame = pd.read_sql('select * from '+vtabela, dbConnection);\n",
    "query='select count(*) from '+vtabela\n",
    "try:\n",
    "    numero = pd.read_sql(query,dbConnection)\n",
    "    n=numero['count(*)'][0]\n",
    "except:\n",
    "    n=0\n",
    "print(n)\n",
    "reg=2040\n",
    "while reg<n:\n",
    "        nomearq='itens'+frame['identificador'][reg]+'.json'\n",
    "        url = 'http://compras.dados.gov.br/licitacoes/id/licitacao/'+frame['identificador'][reg]+'/itens.json'\n",
    "        try:\n",
    "            response = urlopen(url)\n",
    "            data_json = json.loads(response.read())\n",
    "            with open(path+\"\\\\\"+nomearq,'w') as f:\n",
    "                json.dump(data_json,f)\n",
    "        except HTTPError as e:\n",
    "            print(e.code)\n",
    "            print(e.read()) \n",
    "        except URLError as u:\n",
    "             print('Erro de URL')\n",
    "        reg += 1\n",
    "        print(reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ee086b",
   "metadata": {},
   "source": [
    "# Carga de pregões"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e02484b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "from urllib.request import urlopen\n",
    "from urllib.error import URLError, HTTPError\n",
    "import pymysql\n",
    "import datetime\n",
    "from dateutil.relativedelta import *\n",
    "from datetime import date\n",
    "import json\n",
    "from sqlalchemy.dialects.mysql import insert\n",
    "import pandas as pd\n",
    "import pandas as pd2\n",
    "\n",
    "def insert_on_duplicate(table, conn, keys, data_iter):\n",
    "    insert_stmt = insert(table.table).values(list(data_iter))\n",
    "    on_duplicate_key_stmt = insert_stmt.on_duplicate_key_update(insert_stmt.inserted)\n",
    "    conn.execute(on_duplicate_key_stmt)\n",
    "\n",
    "sqlEngine       = create_engine('mysql+pymysql://siasg:siasg@192.168.2.135/siasg', pool_recycle=3600)\n",
    "dbConnection    = sqlEngine.connect()\n",
    "\n",
    "# specify your path of directory\n",
    "path = \".\\\\json\\\\pregoes\"\n",
    "\n",
    "vtabela='licitacoes'\n",
    "frame = pd.read_sql('select * from '+vtabela, dbConnection);\n",
    "query='select count(*) from '+vtabela\n",
    "try:\n",
    "    numero = pd.read_sql(query,dbConnection)\n",
    "    n=numero['count(*)'][0]\n",
    "except:\n",
    "    n=0\n",
    "print(n)\n",
    "reg=1\n",
    "while reg<n:\n",
    "        nomearq='itenspregoes'+frame['identificador'][reg]+'.json'\n",
    "        url = 'http://compras.dados.gov.br/pregoes/id/pregao/'+frame['identificador'][reg]+'/itens.json'\n",
    "        print(url)\n",
    "        try:\n",
    "            response = urlopen(url)\n",
    "            data_json = json.loads(response.read())\n",
    "            with open(path+\"\\\\\"+nomearq,'w') as f:\n",
    "                json.dump(data_json,f)\n",
    "        except HTTPError as e:\n",
    "            print(e.code)\n",
    "            print(e.read()) \n",
    "        except URLError as u:\n",
    "             print('Erro de URL')\n",
    "        reg += 1\n",
    "        print(reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b18c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "from urllib.request import urlopen\n",
    "from urllib.error import URLError, HTTPError\n",
    "import pymysql\n",
    "import datetime\n",
    "from dateutil.relativedelta import *\n",
    "from datetime import date\n",
    "import json\n",
    "from sqlalchemy.dialects.mysql import insert\n",
    "import pandas as pd\n",
    "import pandas as pd2\n",
    "\n",
    "def insert_on_duplicate(table, conn, keys, data_iter):\n",
    "    insert_stmt = insert(table.table).values(list(data_iter))\n",
    "    on_duplicate_key_stmt = insert_stmt.on_duplicate_key_update(insert_stmt.inserted)\n",
    "    conn.execute(on_duplicate_key_stmt)\n",
    "\n",
    "sqlEngine       = create_engine('mysql+pymysql://siasg:siasg@192.168.2.135/siasg', pool_recycle=3600)\n",
    "dbConnection    = sqlEngine.connect()\n",
    "\n",
    "# specify your path of directory\n",
    "path = \".\\\\json\\\\precospraticados\"\n",
    "\n",
    "vtabela='licitacoes'\n",
    "frame = pd.read_sql('select * from '+vtabela, dbConnection);\n",
    "query='select count(*) from '+vtabela\n",
    "try:\n",
    "    numero = pd.read_sql(query,dbConnection)\n",
    "    n=numero['count(*)'][0]\n",
    "except:\n",
    "    n=0\n",
    "print(n)\n",
    "reg=0\n",
    "while reg<n:\n",
    "        nomearq='precospraticados'+frame['identificador'][reg]+'.json'       \n",
    "        url = 'http://compras.dados.gov.br/licitacoes/id/preco_praticado/'+frame['identificador'][reg]+'/itens.json'\n",
    "        try:\n",
    "            response = urlopen(url)\n",
    "            data_json = json.loads(response.read())\n",
    "            with open(path+\"\\\\\"+nomearq,'w') as f:\n",
    "                json.dump(data_json,f)\n",
    "        except HTTPError as e:\n",
    "            print(e.code)\n",
    "            print(e.read()) \n",
    "        except URLError as u:\n",
    "             print('Erro de URL')\n",
    "        reg += 1\n",
    "        print(reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc06cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "from urllib.request import urlopen\n",
    "from urllib.error import URLError, HTTPError\n",
    "import pymysql\n",
    "import datetime\n",
    "from dateutil.relativedelta import *\n",
    "from datetime import date\n",
    "import json\n",
    "from sqlalchemy.dialects.mysql import insert\n",
    "import pandas as pd\n",
    "import pandas as pd2\n",
    "\n",
    "def insert_on_duplicate(table, conn, keys, data_iter):\n",
    "    insert_stmt = insert(table.table).values(list(data_iter))\n",
    "    on_duplicate_key_stmt = insert_stmt.on_duplicate_key_update(insert_stmt.inserted)\n",
    "    conn.execute(on_duplicate_key_stmt)\n",
    "\n",
    "sqlEngine       = create_engine('mysql+pymysql://siasg:siasg@192.168.2.135/siasg', pool_recycle=3600)\n",
    "dbConnection    = sqlEngine.connect()\n",
    "\n",
    "# specify your path of directory\n",
    "path = \".\\\\json\\\\precospraticados\"\n",
    "\n",
    "vtabela='licitacoes'\n",
    "frame = pd.read_sql('select * from '+vtabela, dbConnection);\n",
    "query='select count(*) from '+vtabela\n",
    "try:\n",
    "    numero = pd.read_sql(query,dbConnection)\n",
    "    n=numero['count(*)'][0]\n",
    "except:\n",
    "    n=0\n",
    "print(n)\n",
    "reg=0\n",
    "while reg<n:\n",
    "        nomearq='precospraticados'+frame['identificador'][reg]+'.json'       \n",
    "        url = 'http://compras.dados.gov.br/licitacoes/id/preco_praticado/'+frame['identificador'][reg]+'/itens.json'\n",
    "        try:\n",
    "            response = urlopen(url)\n",
    "            data_json = json.loads(response.read())\n",
    "            with open(path+\"\\\\\"+nomearq,'w') as f:\n",
    "                json.dump(data_json,f)\n",
    "        except HTTPError as e:\n",
    "            print(e.code)\n",
    "            print(e.read()) \n",
    "        except URLError as u:\n",
    "             print('Erro de URL')\n",
    "        reg += 1\n",
    "        print(reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7decd56",
   "metadata": {},
   "source": [
    "# Carga dos Itens da Licitação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103f4254",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import os\n",
    "import pymysql\n",
    "import json\n",
    "from sqlalchemy.dialects.mysql import insert\n",
    "import pandas as pd\n",
    "import pandas as pd2\n",
    "\n",
    "vtabela='itensLicitacao'\n",
    "\n",
    "def insert_on_duplicate(table, conn, keys, data_iter):\n",
    "    insert_stmt = insert(table.table).values(list(data_iter))\n",
    "    on_duplicate_key_stmt = insert_stmt.on_duplicate_key_update(insert_stmt.inserted)\n",
    "    conn.execute(on_duplicate_key_stmt)\n",
    "    \n",
    "sqlEngine       = create_engine('mysql+pymysql://siasg:siasg@192.168.2.135/siasg', pool_recycle=3600)\n",
    "dbConnection    = sqlEngine.connect()\n",
    " \n",
    "# specify your path of directory\n",
    "path = \".\\\\json\\\\itens\"\n",
    " \n",
    "directories = os.listdir( path )\n",
    "i=1\n",
    "for file in directories:\n",
    "    nomearq=file\n",
    "    print(str(i)+\" \"+nomearq)\n",
    "    try: \n",
    "        with open(path+\"\\\\\"+nomearq, encoding=\"utf8\") as json_file:\n",
    "            data_json = json.loads(json_file.read())\n",
    "    except:\n",
    "        print(\"Erro na abertura do arquivo \"+nomearq)\n",
    "    try: \n",
    "        embedded = data_json[\"_embedded\"]\n",
    "        tb= embedded['itensLicitacao']\n",
    "    except:\n",
    "        print(\"Erro na preparação do \"+nomearq)\n",
    "    try: \n",
    "        df = pd2.DataFrame.from_dict(tb, orient='columns')\n",
    "        del df['_links']\n",
    "    except:\n",
    "        print(\"Erro na leitura do \"+nomearq)\n",
    "    try:\n",
    "        df.to_sql(vtabela, sqlEngine, if_exists='append', index=False, method=insert_on_duplicate)\n",
    "    except:\n",
    "        print(\"Erro na gravação do arquivo \"+nomearq)\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d6e33c8",
   "metadata": {},
   "source": [
    "# Carga dos Preços praticados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f96420",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import os\n",
    "import pymysql\n",
    "import json\n",
    "from sqlalchemy.dialects.mysql import insert\n",
    "import pandas as pd\n",
    "import pandas as pd2\n",
    "\n",
    "vtabela='itensPrecoPraticado'\n",
    "\n",
    "def insert_on_duplicate(table, conn, keys, data_iter):\n",
    "    insert_stmt = insert(table.table).values(list(data_iter))\n",
    "    on_duplicate_key_stmt = insert_stmt.on_duplicate_key_update(insert_stmt.inserted)\n",
    "    conn.execute(on_duplicate_key_stmt)\n",
    "    \n",
    "sqlEngine       = create_engine('mysql+pymysql://siasg:siasg@192.168.2.135/siasg', pool_recycle=3600)\n",
    "dbConnection    = sqlEngine.connect()\n",
    " \n",
    "# specify your path of directory\n",
    "path = \".\\\\json\\\\precospraticados\"\n",
    " \n",
    "directories = os.listdir( path )\n",
    "i=1\n",
    "for file in directories:\n",
    "    nomearq=file\n",
    "    print(str(i)+ \" - \"+nomearq)\n",
    "    try: \n",
    "        with open(path+\"\\\\\"+nomearq, encoding=\"utf8\") as json_file:\n",
    "            data_json = json.loads(json_file.read())\n",
    "    except:\n",
    "        print(\"Erro na abertura do arquivo \"+nomearq)\n",
    "    try: \n",
    "        embedded = data_json[\"_embedded\"]\n",
    "        tb= embedded['itensPrecoPraticado']\n",
    "    except:\n",
    "        print(\"Erro na preparação do \"+nomearq)\n",
    "    try: \n",
    "        df = pd2.DataFrame.from_dict(tb, orient='columns')\n",
    "        if '_links' in df.columns: \n",
    "            del df['_links']\n",
    "    except:\n",
    "        print(\"Erro na leitura do \"+nomearq)\n",
    "    try:\n",
    "        df.to_sql(vtabela, sqlEngine, if_exists='append', index=False, method=insert_on_duplicate)\n",
    "    except:\n",
    "        print(\"Erro na gravação do arquivo \"+nomearq)\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6a19bb",
   "metadata": {},
   "source": [
    "# Busca de Materiais na API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d149c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SELECT distinct codigo_item_material FROM siasg.itensLicitacao where !(codigo_item_material is null);\n",
    "# http://compras.dados.gov.br/materiais/id/material/000227505.json\n",
    "# str(num).zfill(9) \n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "from urllib.request import urlopen\n",
    "from urllib.error import URLError, HTTPError\n",
    "import pymysql\n",
    "import datetime\n",
    "from dateutil.relativedelta import *\n",
    "from datetime import date\n",
    "import json\n",
    "from sqlalchemy.dialects.mysql import insert\n",
    "import pandas as pd\n",
    "import pandas as pd2\n",
    "import os\n",
    "\n",
    "def insert_on_duplicate(table, conn, keys, data_iter):\n",
    "    insert_stmt = insert(table.table).values(list(data_iter))\n",
    "    on_duplicate_key_stmt = insert_stmt.on_duplicate_key_update(insert_stmt.inserted)\n",
    "    conn.execute(on_duplicate_key_stmt)\n",
    "print('Comecei')\n",
    "sqlEngine       = create_engine('mysql+pymysql://siasg:siasg@192.168.2.135/siasg', pool_recycle=3600)\n",
    "dbConnection    = sqlEngine.connect()\n",
    "\n",
    "# specify your path of directory\n",
    "path = \".\\\\json\\\\material\"\n",
    "\n",
    "vtabela='licitacoes'\n",
    "frame = pd.read_sql('SELECT distinct codigo_item_material FROM siasg.itensLicitacao where codigo_item_material is not null order by codigo_item_material', dbConnection);\n",
    "print(frame)\n",
    "for row in frame.codigo_item_material:\n",
    "        nomearq='material'+str(row).zfill(9)+'.json'\n",
    "        arquivo=path+\"\\\\\"+nomearq\n",
    "#        if row<150000: continue\n",
    "        if not (os.path.exists(arquivo)): \n",
    "            print('Fazendo '+str(row))\n",
    "            url = 'http://compras.dados.gov.br/materiais/id/material/'+str(row).zfill(9)+'.json'\n",
    "            try:\n",
    "                response = urlopen(url)\n",
    "                data_json = json.loads(response.read())\n",
    "                with open(path+\"\\\\\"+nomearq,'w') as f:\n",
    "                    json.dump(data_json,f)\n",
    "            except HTTPError as e:\n",
    "                print('Erro'+str(e.code))\n",
    "            except URLError as u:\n",
    "                print('Erro de URL')\n",
    "print('Concluído')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98f1f03",
   "metadata": {},
   "source": [
    "# Carga dos JSON de Materiais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f8d809",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import os\n",
    "import pymysql\n",
    "import json\n",
    "from sqlalchemy.dialects.mysql import insert\n",
    "import pandas as pd\n",
    "import pandas as pd2\n",
    "\n",
    "vtabela='materiais'\n",
    "\n",
    "def insert_on_duplicate(table, conn, keys, data_iter):\n",
    "    insert_stmt = insert(table.table).values(list(data_iter))\n",
    "    on_duplicate_key_stmt = insert_stmt.on_duplicate_key_update(insert_stmt.inserted)\n",
    "    conn.execute(on_duplicate_key_stmt)\n",
    "    \n",
    "sqlEngine       = create_engine('mysql+pymysql://siasg:siasg@192.168.2.135/siasg', pool_recycle=3600)\n",
    "dbConnection    = sqlEngine.connect()\n",
    " \n",
    "# specify your path of directory\n",
    "path = \".\\\\json\\\\material\"\n",
    " \n",
    "directories = os.listdir( path )\n",
    "i=1\n",
    "for file in directories:\n",
    "    nomearq=file\n",
    "    print(str(i)+ \" - \"+nomearq)\n",
    "    try: \n",
    "        with open(path+\"\\\\\"+nomearq, encoding=\"utf8\") as json_file:\n",
    "            data_json = json.loads(json_file.read())\n",
    "    except:\n",
    "        print(\"Erro na abertura do arquivo \"+nomearq)\n",
    "    try: \n",
    "        tb = data_json\n",
    "    except:\n",
    "        print(\"Erro na preparação do \"+nomearq)\n",
    "    try: \n",
    "        df = pd2.DataFrame.from_dict(tb, orient='columns')\n",
    "        if '_links' in df.columns: \n",
    "            del df['_links']\n",
    "    except:\n",
    "        print(\"Erro na leitura do \"+nomearq)\n",
    "    try:\n",
    "        df.to_sql(vtabela, sqlEngine, if_exists='append', index=False, method=insert_on_duplicate)\n",
    "    except:\n",
    "        print(\"Erro na gravação do arquivo \"+nomearq)\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29a345d",
   "metadata": {},
   "source": [
    "# Carregar PDM e Classe nos itens de preço"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893bd0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import os\n",
    "import pymysql\n",
    "import json\n",
    "from sqlalchemy.dialects.mysql import insert\n",
    "import pandas as pd\n",
    "import pandas as pd2\n",
    "\n",
    "def insert_on_duplicate(table, conn, keys, data_iter):\n",
    "    insert_stmt = insert(table.table).values(list(data_iter))\n",
    "    on_duplicate_key_stmt = insert_stmt.on_duplicate_key_update(insert_stmt.inserted)\n",
    "    conn.execute(on_duplicate_key_stmt)  \n",
    "    \n",
    "sqlEngine       = create_engine('mysql+pymysql://siasg:siasg@192.168.2.135/siasg', pool_recycle=3600)\n",
    "dbConnection    = sqlEngine.connect()\n",
    "\n",
    "frame = pd.read_sql('SELECT * FROM siasg.itensPrecoPraticado where !(codigo_item_material is null)', dbConnection);\n",
    "for index,row in frame.iterrows():\n",
    "    cod=row['codigo_item_material']\n",
    "    frame2= pd2.read_sql('SELECT id_classe, id_pdm, descricao from siasg.materiais where codigo='+str(cod),dbConnection)\n",
    "    if frame2.size>0:\n",
    "        classe=frame2['id_classe'][0]\n",
    "        pdm=frame2['id_pdm'][0]\n",
    "        descricao = frame2['descricao'][0]\n",
    "    else: \n",
    "        classe=0\n",
    "        pdm=0\n",
    "        descricao=''\n",
    "    frame.at[index,'codigo_pdm']=pdm\n",
    "    frame.at[index,'codigo_classe']=classe\n",
    "    frame.at[index, 'descricao_material']=descricao\n",
    "    # ######################  Descritor PDM\n",
    "    frame2= pd2.read_sql('SELECT descricao from siasg.pdms where codigo='+str(pdm),dbConnection)\n",
    "    if frame2.size>0:\n",
    "        descricao = frame2['descricao'][0]\n",
    "    else: \n",
    "        descricao=''   \n",
    "    frame.at[index, 'descricao_pdm']=descricao\n",
    "    print(str(index)+' concluído')\n",
    "frame.to_sql('Bancodeteste', dbConnection, if_exists='append', index=False, method=insert_on_duplicate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a596036",
   "metadata": {},
   "source": [
    "# Carrega arquivo de licitações diárias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d4cb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from urllib.error import URLError, HTTPError\n",
    "import calendar\n",
    "import json\n",
    "import os\n",
    "\n",
    "# specify your path of directory\n",
    "path = \".\\\\json\\\\licitacoes\\\\diarias\"\n",
    "ano =2022\n",
    "\n",
    "vtabela='licitacoes'\n",
    "for mes in range(1, 13):\n",
    "    udia = calendar.monthrange(ano, mes)[1]\n",
    "    udia1 = udia+1\n",
    "    print(udia1)\n",
    "    for dia in range(1,udia1):\n",
    "        erro=True\n",
    "        while erro:\n",
    "            sdia=str(ano).zfill(4)+'-'+str(mes).zfill(2)+'-'+str(dia).zfill(2)\n",
    "            sudia=str(ano).zfill(4)+'-'+str(mes).zfill(2)+'-'+str(udia).zfill(2)\n",
    "            nomearq='licitacoes'+sdia+'d.json'\n",
    "            arquivo=path+\"\\\\\"+nomearq\n",
    "            #if not (os.path.exists(arquivo)): \n",
    "            print('Fazendo '+sdia)\n",
    "            url = 'http://compras.dados.gov.br/licitacoes/v1/licitacoes.json?data_publicacao='+sdia\n",
    "            print(url)\n",
    "            try:\n",
    "                response = urlopen(url)\n",
    "                data_json = json.loads(response.read())\n",
    "                with open(path+\"\\\\\"+nomearq,'w') as f:\n",
    "                    json.dump(data_json,f)\n",
    "                erro=False\n",
    "            except HTTPError as e:\n",
    "                print('Erro'+str(e.code))\n",
    "            except URLError as u:\n",
    "                print('Erro de URL')\n",
    "print('Concluído')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b990a05d",
   "metadata": {},
   "source": [
    "# Pesquisa Licitações Anuais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e69ffac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from urllib.error import URLError, HTTPError\n",
    "import calendar\n",
    "import json\n",
    "import os\n",
    "\n",
    "# specify your path of directory\n",
    "path = \".\\\\json\\\\licitacoes\\\\novo\"\n",
    "ano =2021\n",
    "\n",
    "vtabela='licitacoes'\n",
    "inicio=str(ano).zfill(4)+'-01-01'\n",
    "fim=str(ano).zfill(4)+'-12-31'\n",
    "nomearq=vtabela+str(ano).zfill(4)+'.json'\n",
    "arquivo=path+\"\\\\\"+nomearq\n",
    "if not (os.path.exists(arquivo)): \n",
    "    print('Fazendo '+nomearq)\n",
    "    url = 'http://compras.dados.gov.br/licitacoes/v1/licitacoes.json?item_material_classificacao=7010&data_publicacao_min='+inicio+'&data_publicacao_max='+fim\n",
    "    print(url)\n",
    "    try:\n",
    "        response = urlopen(url)\n",
    "        data_json = json.loads(response.read())\n",
    "        with open(path+\"\\\\\"+nomearq,'w') as f:\n",
    "            json.dump(data_json,f)\n",
    "    except HTTPError as e:\n",
    "        print('Erro'+str(e.code))\n",
    "    except URLError as u:\n",
    "        print('Erro de URL')\n",
    "print('Concluído')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2c5e1d",
   "metadata": {},
   "source": [
    "# Baixar Licitações Mensais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa87a62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "29\n",
      "32\n",
      "Fazendo 2022-03\n",
      "http://compras.dados.gov.br/licitacoes/v1/licitacoes.json?item_material_classificacao=7010&data_publicacao_min=2022-03-01&data_publicacao_max=2022-03-31\n",
      "Erro500\n",
      "31\n",
      "Fazendo 2022-04\n",
      "http://compras.dados.gov.br/licitacoes/v1/licitacoes.json?item_material_classificacao=7010&data_publicacao_min=2022-04-01&data_publicacao_max=2022-04-30\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from urllib.error import URLError, HTTPError\n",
    "import calendar\n",
    "import json\n",
    "import os\n",
    "\n",
    "# specify your path of directory\n",
    "path = \".\\\\json\\\\licitacoes\\\\novo\"\n",
    "ano =2022\n",
    "\n",
    "vtabela='licitacoes'\n",
    "for mes in range(1, 13):\n",
    "    udia = calendar.monthrange(ano, mes)[1]\n",
    "    udia1 = udia+1\n",
    "    print(udia1)\n",
    "    smes = str(ano).zfill(4)+'-'+str(mes).zfill(2)\n",
    "    inicio=smes+'-'+str(1).zfill(2)\n",
    "    fim=smes+'-'+str(udia).zfill(2)\n",
    "    nomearq='licitacoes'+smes+'m.json'\n",
    "    arquivo=path+\"\\\\\"+nomearq\n",
    "    if not (os.path.exists(arquivo)): \n",
    "        print('Fazendo '+smes)\n",
    "        url = 'http://compras.dados.gov.br/licitacoes/v1/licitacoes.json?item_material_classificacao=7010&data_publicacao_min='+inicio+'&data_publicacao_max='+fim\n",
    "        print(url)\n",
    "        try:\n",
    "            response = urlopen(url)\n",
    "            data_json = json.loads(response.read())\n",
    "            with open(path+\"\\\\\"+nomearq,'w') as f:\n",
    "                json.dump(data_json,f)\n",
    "        except HTTPError as e:\n",
    "            print('Erro'+str(e.code))\n",
    "        except URLError as u:\n",
    "            print('Erro de URL')\n",
    "print('Concluído')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3da8ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
